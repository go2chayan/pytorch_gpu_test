{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GPU_Utilization_Test_in_pytorch","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"LQgy3k5H9dqS","colab_type":"text"},"cell_type":"markdown","source":["#Preparation\n","##Uploading or Using Notebook\n","You need to signup and apply for access before you can start using Google Colab.\n","Once you have access, you can either upload your own notebook using File → Upload Notebook or simply enter your codes in the cells.\n","##Activating GPU\n","To enable GPU backend for your notebook, go to Edit → Notebook Settings and set Hardware accelerator to GPU.\n"]},{"metadata":{"id":"m2_ZIRlA9yrq","colab_type":"text"},"cell_type":"markdown","source":["##Installing Pytorch\n","We are going to use pytorch for tensor operations in GPU. Install pytorch using the following command. Doing it once is sufficient for a session."]},{"metadata":{"id":"IV-EO8xCVpUu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":156},"outputId":"482f1cb6-a88d-407e-f17c-f439ebc7a605","executionInfo":{"status":"ok","timestamp":1525065975690,"user_tz":240,"elapsed":41543,"user":{"displayName":"M. Iftekhar Tanveer","photoUrl":"//lh3.googleusercontent.com/-z7ZDRS1RtoA/AAAAAAAAAAI/AAAAAAAApt4/8496vdCuKj8/s50-c-k-no/photo.jpg","userId":"102883633648680003998"}}},"cell_type":"code","source":["# http://pytorch.org/\n","!pip install torch\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://legacy.pypi.org/simple\r\n","Collecting torch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/a4/7f5ec6e9df1bf13f1881353702aa9713fcd997481b26018f35e0be85faf7/torch-0.4.0-cp27-cp27mu-manylinux1_x86_64.whl (484.0MB)\n","\u001b[K    100% |████████████████████████████████| 484.0MB 25kB/s \n","tcmalloc: large alloc 1073750016 bytes == 0x55aead97c000 @  0x7f951e5aa1c4 0x55ae51a3e0d8 0x55ae51b27d5d 0x55ae51a5177a 0x55ae51a56462 0x55ae51a4eb3a 0x55ae51a5682e 0x55ae51a4eb3a 0x55ae51a5682e 0x55ae51a4eb3a 0x55ae51a5682e 0x55ae51a4eb3a 0x55ae51a56e1f 0x55ae51a4eb3a 0x55ae51a5682e 0x55ae51a4eb3a 0x55ae51a5682e 0x55ae51a56462 0x55ae51a56462 0x55ae51a4eb3a 0x55ae51a56e1f 0x55ae51a56462 0x55ae51a4eb3a 0x55ae51a56e1f 0x55ae51a4eb3a 0x55ae51a56e1f 0x55ae51a4eb3a 0x55ae51a5682e 0x55ae51a4eb3a 0x55ae51a7f50f 0x55ae51a7a202\n","\u001b[?25hInstalling collected packages: torch\n","Successfully installed torch-0.4.0\n"],"name":"stdout"}]},{"metadata":{"id":"5dezNaEF0mMt","colab_type":"text"},"cell_type":"markdown","source":["# Variable Initialization\n","We are going to initializa a big matrix in CPU and another equally sized matrix in GPU"]},{"metadata":{"id":"eIXcGP3yV6lH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"f13b1daf-00ba-4ed3-9da7-21590519e229","executionInfo":{"status":"ok","timestamp":1525066060595,"user_tz":240,"elapsed":12839,"user":{"displayName":"M. Iftekhar Tanveer","photoUrl":"//lh3.googleusercontent.com/-z7ZDRS1RtoA/AAAAAAAAAAI/AAAAAAAApt4/8496vdCuKj8/s50-c-k-no/photo.jpg","userId":"102883633648680003998"}}},"cell_type":"code","source":["import torch\n","import time\n","import numpy as np\n","from torch.autograd import Variable\n","\n","x_cpu = np.random.rand(10000,10000)\n","x_gpu = Variable(torch.from_numpy(x_cpu)).cuda(0)\n","print 'GPU matrix size:',x_gpu.shape\n","print 'CPU matrix size:',x_cpu.shape\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["GPU matrix size: torch.Size([10000, 10000])\n","CPU matrix size: (10000, 10000)\n"],"name":"stdout"}]},{"metadata":{"id":"9TztI4lW3zZv","colab_type":"text"},"cell_type":"markdown","source":["# CPU vs. GPU Comparison for Matrix Multiplication"]},{"metadata":{"id":"ir7rD5IIxPrE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"88b1ed85-fa8d-4ef7-b060-135d306ac173","executionInfo":{"status":"ok","timestamp":1525029995816,"user_tz":240,"elapsed":36606,"user":{"displayName":"M. Iftekhar Tanveer","photoUrl":"//lh3.googleusercontent.com/-z7ZDRS1RtoA/AAAAAAAAAAI/AAAAAAAApt4/8496vdCuKj8/s50-c-k-no/photo.jpg","userId":"102883633648680003998"}}},"cell_type":"code","source":["# Compute in CPU\n","oldtime = time.time()\n","z_cpu = x_cpu.dot(x_cpu.T)\n","print 'Matrix-Matrix product time in CPU:',time.time()-oldtime,'seconds'\n","\n","# Compute in GPU\n","oldtime = time.time()\n","z_cpu = torch.matmul(x_gpu,torch.t(x_gpu))\n","print 'Matrix-Matrix product time in GPU:',time.time()-oldtime,'seconds'"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Matrix-Matrix product time in CPU: 36.3066530228 seconds\n","Matrix-Matrix product time in GPU: 0.000468969345093 seconds\n"],"name":"stdout"}]},{"metadata":{"id":"cQz-jPqS86Ta","colab_type":"text"},"cell_type":"markdown","source":["#CPU vs. GPU Comparison for Random Row-Column Multiplication"]},{"metadata":{"id":"8_3QFk1_4abY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":102},"outputId":"aa90a4f4-7f55-47e9-b50d-3cae706bd220","executionInfo":{"status":"ok","timestamp":1525066879174,"user_tz":240,"elapsed":34860,"user":{"displayName":"M. Iftekhar Tanveer","photoUrl":"//lh3.googleusercontent.com/-z7ZDRS1RtoA/AAAAAAAAAAI/AAAAAAAApt4/8496vdCuKj8/s50-c-k-no/photo.jpg","userId":"102883633648680003998"}}},"cell_type":"code","source":["from itertools import izip\n","\n","m,n = x_cpu.shape\n","idx_a = np.random.choice(np.arange(m),50000)\n","idx_b = np.random.choice(np.arange(m),50000)\n","\n","# Compute in CPU\n","oldtime = time.time()\n","for i,j in izip(idx_a,idx_b):\n","  row = x_cpu[i,:][None,:]\n","  col = x_cpu[:,j][:,None]\n","  z_cpu = row.dot(col)\n","print \"Random row-column multiplication in CPU:\",time.time()-oldtime,'seconds'\n","\n","# Compute in GPU\n","oldtime = time.time()\n","for i,j in izip(idx_a,idx_b):\n","  row = x_gpu[i,:].unsqueeze(0)\n","  col = x_gpu[:,j].unsqueeze(1)\n","  z_gpu = torch.matmul(row,col)\n","print \"Random row-column multiplication (unsqueeze) in GPU:\",time.time()-oldtime,'seconds'\n","\n","# Compute in GPU\n","oldtime = time.time()\n","for i,j in izip(idx_a,idx_b):\n","  row = x_gpu[i,:].view(1,-1)\n","  col = x_gpu[:,j].view(-1,1)\n","  z_gpu = torch.matmul(row,col)\n","print \"Random row-column multiplication (view) in GPU:\",time.time()-oldtime,'seconds'\n","print \"View is a bit slower\"\n","\n","# Compute in GPU\n","oldtime = time.time()\n","for i,j in izip(idx_a,idx_b):\n","  row = x_gpu[i,:].unsqueeze(0)\n","  col = x_gpu[:,j].unsqueeze(1)\n","  z_gpu = torch.mm(row,col)\n","print \"Random row-column multiplication (mm) in GPU:\",time.time()-oldtime,'seconds'\n","  \n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Random row-column multiplication in CPU: 10.2146840096 seconds\n","Random row-column multiplication (unsqueeze) in GPU: 7.92783904076 seconds\n","Random row-column multiplication (view) in GPU: 8.39130401611 seconds\n","View is a bit slower\n","Random row-column multiplication (mm) in GPU: 7.79804587364 seconds\n"],"name":"stdout"}]}]}